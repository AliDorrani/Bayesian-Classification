{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment #3 - AI Fall 98\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "در این پروژه قصد پیاده سازی برنامه ای را داریم که بتواند شاعر یک بیت شعر را تشخیص دهد.\n",
    "ابتدا با بررسی مشخصات و حالات بهترین ویژگی هارا برای تشخیص شاعر پیدا کرده و الگوریتم مربوطه را پیاده سازی می کنیم. \n",
    "برای این منظور ۸۰٪ از اطلاعات در اختیار قرار داده شده را به عنوان ترین ـ دیتا بررسی کرده و باقی ۲۰٪ باقیمانده را برای بررسی نگه می داریم.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ابتدا کتابخانه های مورد نیاز و دستورات لودینگ دیتاها را اجرا می کنیم.\n",
    "\n",
    "سپس برای انتخاب ۸۰٪ دیتای مورد نیاز به صورت رندوم اقدام می کنیم."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import DataFrame, read_csv\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import re\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "\n",
    "file = 'train_test.csv'\n",
    "file_evaluate = 'evaluate.csv'\n",
    "Data = pd.read_csv(file)\n",
    "\n",
    "poems = Data['text']\n",
    "statuses = Data['label']\n",
    "numberOfpoems = len(poems)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "train_index = random.sample(range(0,numberOfpoems), int(.8 * numberOfpoems))\n",
    "test_index = list(set([item for item in range(0, numberOfpoems)]) - set(train_index))\n",
    "hafez_poems_in_train_data = []\n",
    "saadi_poems_in_train_data = []\n",
    "total_vocab_in_train_data = {}\n",
    "hafez_vocab_in_train_data = {}\n",
    "saadi_vocab_in_train_data = {}\n",
    "\n",
    "\n",
    "train_index.sort()\n",
    "test_index.sort()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "سپس برای دقیق تر کار کردن و فهم بهتر شعر های هر شاعر را به صورت تفکیک شده ذخیره می کنیم.\n",
    "\n",
    "پس از آن احتمال تعلق شعر به هر شاعر را نسبت به تعداد اشعار آن شاعر حساب می کنیم\n",
    "\n",
    "به صورت همزمان تعداد کلمات مجزا را در دیتا ترین به دست می آوریم"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for index in train_index:\n",
    "    poem = poems[index]\n",
    "    words = poem.split(' ')\n",
    "    if statuses[index] == 'hafez' :\n",
    "        hafez_poems_in_train_data.append(poems[index])\n",
    "    elif statuses[index] == 'saadi' :\n",
    "        saadi_poems_in_train_data.append(poems[index])\n",
    "    for word in words:\n",
    "        if word not in total_vocab_in_train_data:\n",
    "            total_vocab_in_train_data[word] = 0\n",
    "        else:\n",
    "            total_vocab_in_train_data[word]+=1\n",
    "\n",
    "\n",
    "probability_hafez = (len(hafez_poems_in_train_data) / float(len(train_index)) )\n",
    "probability_saadi = (len(saadi_poems_in_train_data) / float(len(train_index)) )\n",
    "unique_words = 0 \n",
    "unique_words = len(total_vocab_in_train_data)\n",
    "total_vocab_size_unique_word = len(total_vocab_in_train_data)\n",
    "\n",
    "num_total_word_vocab_not_unique = 0\n",
    "for key in total_vocab_in_train_data :\n",
    "    num_total_word_vocab_not_unique+=total_vocab_in_train_data[key]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "در این قسمت با کمک تابع زیر تعداد کلمات مجزا را نیز برای شاعر ها به دست آورده و همینطور تعداد تکرار کلمات در اشعار حافظ و سعدی را به دست می آوریم"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def recognizer(poems_td, vocab_td):\n",
    "    for poem in poems_td:\n",
    "        words = poem.split(' ')\n",
    "        for word in words:\n",
    "            if word not in vocab_td:\n",
    "                vocab_td[word] = 0\n",
    "            else:\n",
    "                vocab_td[word]+=1\n",
    "    return vocab_td\n",
    "\n",
    "\n",
    "unique_words = 0 \n",
    "unique_words = len(total_vocab_in_train_data)\n",
    "hafez_vocab_in_train_data = recognizer(hafez_poems_in_train_data,hafez_vocab_in_train_data)\n",
    "saadi_vocab_in_train_data = recognizer(saadi_poems_in_train_data,saadi_vocab_in_train_data)\n",
    "   \n",
    "\n",
    "num_total_word_saadi_unique = len(saadi_vocab_in_train_data) \n",
    "num_total_word_saadi_not_unique = 0\n",
    "for key in saadi_vocab_in_train_data :\n",
    "    num_total_word_saadi_not_unique += saadi_vocab_in_train_data[key]\n",
    "\n",
    "\n",
    "num_total_word_hafez_unique = len(hafez_vocab_in_train_data) \n",
    "num_total_word_hafez_not_unique = 0\n",
    "for key in hafez_vocab_in_train_data :\n",
    "    num_total_word_hafez_not_unique+=hafez_vocab_in_train_data[key]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "دیتا های به دست آمده به شرح زیر می باشد :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Number Of Poems in train_test: 20889\n",
      "hafez poems count in 80% train data: 6722\n",
      "saadi poems count in 80% train data: 9989\n",
      "probability hafez: 0.40225001496020585\n",
      "probability saadi: 0.5977499850397942\n",
      "num_total_word_vocab_not_unique 109336\n",
      "total_vocab_size_unique_word 12672\n",
      "num poem in train data 16711\n",
      "num_total_word_hafez_not_unique: 43287\n",
      "num_total_word_hafez_unique 7376\n",
      "num_total_word_saadi_not_unique: 62124\n",
      "num_total_word_saadi_unique 9221\n"
     ]
    }
   ],
   "source": [
    "print(\"Total Number Of Poems in train_test:\",numberOfpoems)\n",
    "print(\"hafez poems count in 80% train data:\",len(hafez_poems_in_train_data))\n",
    "print(\"saadi poems count in 80% train data:\",len(saadi_poems_in_train_data))\n",
    "print(\"probability hafez:\" , probability_hafez)\n",
    "print(\"probability saadi:\" , probability_saadi)\n",
    "print(\"num_total_word_vocab_not_unique\",num_total_word_vocab_not_unique)\n",
    "print(\"total_vocab_size_unique_word\",len(total_vocab_in_train_data))\n",
    "print(\"num poem in train data\",len(train_index))\n",
    "print(\"num_total_word_hafez_not_unique:\",num_total_word_hafez_not_unique)\n",
    "print(\"num_total_word_hafez_unique\",num_total_word_hafez_unique)\n",
    "print(\"num_total_word_saadi_not_unique:\",num_total_word_saadi_not_unique  )\n",
    "print(\"num_total_word_saadi_unique\",num_total_word_saadi_unique)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "حال کافی است که در قسمت نهایی بخش ترین خود به محاسبه احتمال وجود کلمه به شرط انکه شاعرش حافظ یا سعدی باشد می پردازیم .در حقیقت با استفاده از فرمول زیر احتمال را محاسبه می کنیم.\n",
    "\n",
    "p ( wk | Vj )  = nk + 1 / n + |vocabulary |  لاپلاس\n",
    "\n",
    "در اینجا سایز لغات را برابر تعداد کلمات مجزا و\n",
    "عدد\n",
    "ان را\n",
    "را تعداد کل کلماتی که در حافظ و سعدی به کار رفته است در نظر می گیریم."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "p ( w | hafez ) =  تعداد دفعاتی که کلمه مورد نظر در حافظ آمده +۱/  تعداد کماتی که در حافظ آمده + تعداد کلماتی که در کل آمده \n",
    "\n",
    "\n",
    "\n",
    "p ( w | saadi ) =  تعداد دفعاتی که کلمه مورد نظر در سعدی آمده +۱/  تعداد کماتی که در سعدی آمده + تعداد کلماتی که در کل آمده \n",
    "\n",
    "\n",
    "براساس فرمول های فوق احتمال کلمه به شرط لغات محسابه می کنیم. \n",
    "برای مثال وقتی کلمه ای در بیت های ترین سعدی به کار نرفته باشد ولی در بیت های تست دیتا قرار گرفته باشد حاصل ضرب احتمال ۰ می شود ولی با در نظر گرفتن یک احتمال دیگر صفر نمی شود.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_probability_conditional(word,saadi_vocab_in_train_data,total_vocab_in_train_data,\n",
    "                                        num_total_word_saadi_not_unique ,unique_words, condition):\n",
    "    \n",
    "    if(condition == \"Laplace\"):    \n",
    "        num_word_in_saadi = 0\n",
    "        if word in saadi_vocab_in_train_data:\n",
    "            num_word_in_saadi = saadi_vocab_in_train_data[word]\n",
    "        x =  num_word_in_saadi + 1\n",
    "        y = float( num_total_word_saadi_not_unique + len(total_vocab_in_train_data))\n",
    "        return x/y\n",
    "    \n",
    "\n",
    "    elif(condition == \"Simple\"):\n",
    "        num_word_in_saadi = 0\n",
    "        if word in saadi_vocab_in_train_data:\n",
    "            num_word_in_saadi = saadi_vocab_in_train_data[word]\n",
    "        x = num_word_in_saadi + .3\n",
    "        y = float(num_total_word_saadi_not_unique + len(total_vocab_in_train_data))\n",
    "        return x/y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "حال در این قسمت با توجه به دیتا ترین کافی است که از ۲۰ درصد باقی مانده برای تست عملکرد استفاده کنیم .\n",
    "\n",
    "در اینجا سه مقدار را براساس فرمول های داده شده در صورت پروژه بدست خواهیم آورد"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "حال کافی است در هر اندیس دیتا تست بیاییم هر شعر را بررسی کنیم و  دو مقدار زیر را هم برای حافظ و هم برای سعدی حساب کنیم  و هر کدام که بیشتر شد در حقیقت مدل ما آن را پیش بینی کرده است حال با نتیجه جواب مقایسه می کنیم و مقادیر را آپدیت می کنیم\n",
    "\n",
    "\n",
    "\n",
    "این تابع هردو حالت لاپلاس و عادی را به اضای ورودی خواسته شده حساب می کند."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " Unit Test Initialization OutPut :\n",
      "hafez poems count in 20% test data: 1696\n",
      "saadi poems count in 20% test data: 2482\n",
      "num_total_word_vocab_not_unique in 20% test 24776\n",
      "total_vocab_size_unique_word in 20 % test 12672\n",
      "num poem in train data in 20% test 4178\n",
      "num_total_word_hafez_not_unique in 20% test: 93950\n",
      "num_total_word_hafez_unique in 20% test:  7376\n",
      "num_total_word_saadi_not_unique in 20% test: 133469\n",
      "num_total_word_saadi_unique in 20 % test 9221\n",
      "Unit Test Initialization OutPuts Ends \n",
      "\n",
      "\n",
      "\n",
      "\n",
      " '1'.... Laplace \n",
      " '2' ....Simple \n",
      "\n",
      "\n",
      "2\n",
      "Recall in simple: 0.7246462264150944\n",
      "Precision in simple: 0.7595797280593325\n",
      "Accuracy in simple: 0.7951172809956917\n"
     ]
    }
   ],
   "source": [
    "def Unit_Test(test_index,\n",
    "                statuses,\n",
    "                poems,\n",
    "                probability_hafez,\n",
    "                probability_saadi,\n",
    "                total_vocab_in_train_data,\n",
    "                unique_words,\n",
    "                num_total_word_vocab_not_unique,\n",
    "                hafez_vocab_in_train_data,\n",
    "                saadi_vocab_in_train_data,\n",
    "                num_total_word_hafez_unique,\n",
    "                num_total_word_saadi_unique,\n",
    "                num_total_word_hafez_not_unique,\n",
    "                num_total_word_saadi_not_unique):\n",
    "    \n",
    "    hafez_poems_in_test_data = []\n",
    "    saadi_poems_in_test_data = []\n",
    "    num_total_word_vocab_not_unique = 0\n",
    "    total_vocab_in_test_data = {}\n",
    "    hafez_vocab_in_test_data = {}\n",
    "    saadi_vocab_in_test_data = {}\n",
    "    correct_detected_hafezes = 0\n",
    "    detected_hafezes = 0\n",
    "    correct_detected = 0\n",
    "    select_op = 0\n",
    "    num_total_word_hafez_not_unique = 0\n",
    "    num_total_word_saadi_not_unique = 0\n",
    "\n",
    "    for index in test_index :\n",
    "        if statuses[index] == 'hafez' :\n",
    "            hafez_poems_in_test_data.append(poems[index])\n",
    "        elif True:\n",
    "            saadi_poems_in_test_data.append(poems[index])\n",
    "            \n",
    "    hafez_numberOfpoems_in_test_data = len(hafez_poems_in_test_data)\n",
    "    saadi_numberOfpoems_in_test_data = len(saadi_poems_in_test_data)\n",
    " \n",
    "\n",
    "    for index in test_index:\n",
    "        poem = poems[index]\n",
    "        words = poem.split(' ')\n",
    "        for word in words:\n",
    "            if word not in total_vocab_in_test_data:\n",
    "                total_vocab_in_test_data[word] = 0\n",
    "            elif True:\n",
    "                total_vocab_in_test_data[word]+=1\n",
    "            \n",
    "    unique_words = len(total_vocab_in_test_data)\n",
    "\n",
    "    \n",
    "\n",
    "    for key in total_vocab_in_test_data :\n",
    "        num_total_word_vocab_not_unique += total_vocab_in_test_data[key]\n",
    "    \n",
    "\n",
    "    hafez_vocab_in_test_data = recognizer(hafez_poems_in_train_data,hafez_vocab_in_train_data)\n",
    "    saadi_vocab_in_test_data = recognizer(saadi_poems_in_train_data,saadi_vocab_in_train_data)\n",
    "\n",
    "              \n",
    "                \n",
    "    num_total_word_hafez_unique = len(hafez_vocab_in_test_data) \n",
    "    for key in hafez_vocab_in_test_data :\n",
    "        num_total_word_hafez_not_unique += hafez_vocab_in_test_data[key]\n",
    "    \n",
    "    num_total_word_saadi_unique = len(saadi_vocab_in_test_data) \n",
    "\n",
    "    \n",
    "    for key in saadi_vocab_in_test_data :\n",
    "        num_total_word_saadi_not_unique += saadi_vocab_in_test_data[key]\n",
    "\n",
    "    print(\"\\n\\n Unit Test Initialization OutPut :\")\n",
    "    print(\"hafez poems count in 20% test data:\",hafez_numberOfpoems_in_test_data)\n",
    "    print(\"saadi poems count in 20% test data:\",saadi_numberOfpoems_in_test_data)\n",
    "    print(\"num_total_word_vocab_not_unique in 20% test\",num_total_word_vocab_not_unique)\n",
    "    print(\"total_vocab_size_unique_word in 20 % test\",len(total_vocab_in_train_data))\n",
    "    print(\"num poem in train data in 20% test\",len(test_index))\n",
    "    print(\"num_total_word_hafez_not_unique in 20% test:\",num_total_word_hafez_not_unique)\n",
    "    print(\"num_total_word_hafez_unique in 20% test: \",num_total_word_hafez_unique)\n",
    "    print(\"num_total_word_saadi_not_unique in 20% test:\",num_total_word_saadi_not_unique  )\n",
    "    print(\"num_total_word_saadi_unique in 20 % test\",num_total_word_saadi_unique)\n",
    "    print(\"Unit Test Initialization OutPuts Ends \\n\")\n",
    "        \n",
    "    \n",
    "    all_hafezes = len(hafez_poems_in_test_data)\n",
    "    total = len(test_index)\n",
    "    \n",
    "    \n",
    "    select_op = int(input(\"\\n\\n\\n '1'.... Laplace \\n '2' ....Simple \\n\\n\\n\"))\n",
    "    \n",
    "    for index in test_index:\n",
    "        poem = poems[index]\n",
    "        words = poem.split(' ')\n",
    "        p_hafez = probability_hafez\n",
    "        p_saadi = probability_saadi\n",
    "        for word in words:\n",
    "            if(select_op == 2):\n",
    "                p_hafez *= calculate_probability_conditional(word,hafez_vocab_in_train_data,\n",
    "                                                                total_vocab_in_train_data,\n",
    "                                                                num_total_word_hafez_not_unique ,\n",
    "                                                                len(total_vocab_in_train_data),\"Simple\")\n",
    "                \n",
    "                p_saadi *= calculate_probability_conditional(word,saadi_vocab_in_train_data,\n",
    "                                                            total_vocab_in_train_data,\n",
    "                                                                num_total_word_saadi_not_unique ,\n",
    "                                                            len(total_vocab_in_train_data),\"Simple\"  )\n",
    "            if(select_op == 1): \n",
    "                p_hafez *= calculate_probability_conditional(word,hafez_vocab_in_train_data,\n",
    "                                                           total_vocab_in_train_data,\n",
    "                                                            num_total_word_hafez_not_unique ,\n",
    "                                                            len(total_vocab_in_train_data),\"Laplace\")\n",
    "                p_saadi *= calculate_probability_conditional(word,saadi_vocab_in_train_data,total_vocab_in_train_data,\n",
    "                                                            num_total_word_saadi_not_unique , len(total_vocab_in_train_data),\"Laplace\")\n",
    "\n",
    "        if p_hafez > p_saadi:\n",
    "\n",
    "            detected_hafezes += 1\n",
    "            if statuses[index] == 'hafez':\n",
    "                correct_detected_hafezes += 1\n",
    "                correct_detected += 1\n",
    "          \n",
    "        ##model decide saadi\n",
    "        elif p_hafez < p_saadi:\n",
    "            if statuses[index] =='saadi':\n",
    "                correct_detected+=1\n",
    "\n",
    "    recall = correct_detected_hafezes/float(all_hafezes)\n",
    "    precision =  correct_detected_hafezes/ float(detected_hafezes)  \n",
    "    accuracy = correct_detected / float(total)\n",
    "            \n",
    "    if(select_op == 2):\n",
    "        print(\"Recall in simple:\",recall)\n",
    "        print(\"Precision in simple:\",precision)\n",
    "        print(\"Accuracy in simple:\",accuracy)\n",
    "    if (select_op == 1):\n",
    "        print(\"Recall in Laplace:\",recall)\n",
    "        print(\"Precision in Laplace:\",precision)\n",
    "        print(\"Accuracy in Laplace:\",accuracy)\n",
    "\n",
    "\n",
    "\n",
    "Unit_Test(test_index,\n",
    "            statuses,\n",
    "            poems,\n",
    "            probability_hafez,\n",
    "            probability_saadi,\n",
    "            total_vocab_in_train_data,\n",
    "            len(total_vocab_in_train_data),\n",
    "            num_total_word_vocab_not_unique,\n",
    "            hafez_vocab_in_train_data,\n",
    "            saadi_vocab_in_train_data,\n",
    "            num_total_word_hafez_unique,\n",
    "            num_total_word_saadi_unique,\n",
    "            num_total_word_hafez_not_unique,\n",
    "            num_total_word_saadi_not_unique)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall in Laplace: 0.7393681652490887\n",
    "\n",
    "\n",
    "Precision in Laplace: 0.7507711289327575\n",
    "\n",
    "\n",
    "Accuracy in Laplace: 0.8006223073240785"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "اطلاعات به دست آمده از تابع برای هر دو حالت ساده و لاپلاس به صورت بالا است"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "در پایان به ساخت فایل خواسته شده می پردازیم."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def make_evalute_file( evalute_filename ,\n",
    "                    probability_hafez,\n",
    "                    probability_saadi,\n",
    "                    total_vocab_in_train_data,\n",
    "                    unique_words,\n",
    "                    num_total_word_vocab_not_unique,\n",
    "                    hafez_vocab_in_train_data,\n",
    "                    saadi_vocab_in_train_data,\n",
    "                    num_total_word_hafez_unique,\n",
    "                    num_total_word_saadi_unique,\n",
    "                    num_total_word_hafez_not_unique,\n",
    "                    num_total_word_saadi_not_unique):\n",
    "    \n",
    "    Data = pd.read_csv(evalute_filename)\n",
    "    index = Data['id']\n",
    "    poems = Data['text']\n",
    "    statuses = []\n",
    "    for poem in poems:\n",
    "        words = poem.split(' ')\n",
    "        p_hafez = probability_hafez\n",
    "        p_saadi = probability_saadi\n",
    "        for word in words:\n",
    "            p_hafez *= calculate_probability_conditional(word,hafez_vocab_in_train_data,\n",
    "                                                           total_vocab_in_train_data,\n",
    "                                                            num_total_word_hafez_not_unique ,\n",
    "                                                            len(total_vocab_in_train_data),\"Laplace\")\n",
    "            p_saadi *= calculate_probability_conditional(word,saadi_vocab_in_train_data,total_vocab_in_train_data,\n",
    "                                        num_total_word_saadi_not_unique , len(total_vocab_in_train_data),\"Laplace\")\n",
    "            \n",
    "        if p_hafez > p_saadi:\n",
    "            statuses.append('hafez')\n",
    "        elif p_hafez < p_saadi:\n",
    "            statuses.append('saadi')\n",
    "    Data.insert(2,'label',statuses)\n",
    "    print(Data.head(20))\n",
    "    Data.to_csv(\"output.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    id                                   text  label\n",
      "0    1       ور بی تو بامداد کنم روز محشر است  saadi\n",
      "1    2        ساقی بیار جامی کز زهد توبه کردم  hafez\n",
      "2    3          مرا هرآینه خاموش بودن اولی‌تر  saadi\n",
      "3    4   تو ندانی که چرا در تو کسی خیره بماند  saadi\n",
      "4    5         کاینان به دل ربودن مردم معینند  saadi\n",
      "5    6      جان باختن آسان است اندر نظرت لیکن  saadi\n",
      "6    7          گر خاک پای دوست خداوند شوق را  saadi\n",
      "7    8        بی تو در دامن گلزار نخفتم یک شب  saadi\n",
      "8    9      پرده بردار که هوش از تن عاقل برود  saadi\n",
      "9   10         چرا نه در پی عزم دیار خود باشم  hafez\n",
      "10  11        که زندگانی او در هلاک بودن اوست  saadi\n",
      "11  12     که نه هر کو ورقی خواند معانی دانست  hafez\n",
      "12  13  زلف آشفته و خوی کرده و خندان لب و مست  hafez\n",
      "13  14         نسیم موی تو پیوند جان آگه ماست  hafez\n",
      "14  15       من همان روز که روی تو بدیدم گفتم  saadi\n",
      "15  16             اری اسامر لیلای لیله القمر  hafez\n",
      "16  17                تو وفا گر کنی و گر نکنی  saadi\n",
      "17  18       سودا مپز که آتش غم در دل تو نیست  saadi\n",
      "18  19               سخت زیبا می‌روی یک بارگی  saadi\n",
      "19  20             اگر چه رسم خوبان تندخوییست  hafez\n"
     ]
    }
   ],
   "source": [
    "make_evalute_file(file_evaluate ,\n",
    "                    probability_hafez,\n",
    "                    probability_saadi,\n",
    "                    total_vocab_in_train_data,\n",
    "                    len(total_vocab_in_train_data),\n",
    "                    num_total_word_vocab_not_unique,\n",
    "                    hafez_vocab_in_train_data,\n",
    "                    saadi_vocab_in_train_data,\n",
    "                    num_total_word_hafez_unique,\n",
    "                    num_total_word_saadi_unique,\n",
    "                    num_total_word_hafez_not_unique,\n",
    "                    num_total_word_saadi_not_unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
